{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c201488-8760-44b6-b6d9-3ebd83e50ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation des packages n√©cessaires...\n",
      "Installation de earthengine-api...\n",
      "‚úì earthengine-api install√© avec succ√®s\n",
      "‚úì pandas est d√©j√† install√©\n",
      "‚úì numpy est d√©j√† install√©\n",
      "‚úì matplotlib est d√©j√† install√©\n",
      "‚úì geemap est d√©j√† install√©\n",
      "\n",
      "Installation termin√©e !\n"
     ]
    }
   ],
   "source": [
    "# Cellule 1 : Installation des packages\n",
    "print(\"Installation des packages n√©cessaires...\")\n",
    "\n",
    "# Liste des packages √† installer\n",
    "packages = [\n",
    "    \"earthengine-api\",  # Pour Google Earth Engine\n",
    "    \"pandas\",           # Pour les donn√©es tabulaires\n",
    "    \"numpy\",            # Pour les calculs num√©riques\n",
    "    \"matplotlib\",       # Pour les graphiques\n",
    "    \"geemap\"            # Facultatif : pour les cartes interactives\n",
    "]\n",
    "\n",
    "# Installer chaque package\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        # V√©rifier si d√©j√† install√©\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "        print(f\"‚úì {package} est d√©j√† install√©\")\n",
    "    except ImportError:\n",
    "        print(f\"Installation de {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"‚úì {package} install√© avec succ√®s\")\n",
    "\n",
    "print(\"\\nInstallation termin√©e !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d584344-3feb-477f-84e1-f25f203abf3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importation des biblioth√®ques...\n",
      "‚úì Google Earth Engine import√©\n",
      "‚úì pandas import√© (pour les tableaux)\n",
      "‚úì numpy import√© (pour les calculs)\n",
      "‚úì matplotlib import√© (pour les graphiques)\n",
      "\n",
      "Toutes les biblioth√®ques sont import√©es !\n"
     ]
    }
   ],
   "source": [
    "# Cellule 2 : Import des biblioth√®ques\n",
    "print(\"Importation des biblioth√®ques...\")\n",
    "\n",
    "# 1. Google Earth Engine\n",
    "try:\n",
    "    import ee\n",
    "    print(\"‚úì Google Earth Engine import√©\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Erreur avec Google Earth Engine: {e}\")\n",
    "\n",
    "# 2. Analyse de donn√©es\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(\"‚úì pandas import√© (pour les tableaux)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Erreur avec pandas: {e}\")\n",
    "\n",
    "# 3. Calcul num√©rique\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(\"‚úì numpy import√© (pour les calculs)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Erreur avec numpy: {e}\")\n",
    "\n",
    "# 4. Visualisation\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    print(\"‚úì matplotlib import√© (pour les graphiques)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Erreur avec matplotlib: {e}\")\n",
    "\n",
    "print(\"\\nToutes les biblioth√®ques sont import√©es !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e8001e-c2a9-4bc7-9557-4b7527a8c12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIALISATION AVEC TON PROJET GEE\n",
      "============================================================\n",
      "Project ID utilis√© : userscheikhthioub501\n",
      "\n",
      "√âtape 1 : Importation de Google Earth Engine...\n",
      "√âtape 2 : Initialisation...\n",
      "‚úì SUCC√àS ! Google Earth Engine est initialis√©\n",
      "‚úì Projet utilis√© : userscheikhthioub501\n"
     ]
    }
   ],
   "source": [
    "# Cellule 3 : Initialisation avec TON projet\n",
    "print(\"INITIALISATION AVEC TON PROJET GEE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ton project ID exact\n",
    "TON_PROJET = \"userscheikhthioub501\"  # Ton projet\n",
    "print(f\"Project ID utilis√© : {TON_PROJET}\")\n",
    "\n",
    "print(\"\\n√âtape 1 : Importation de Google Earth Engine...\")\n",
    "import ee\n",
    "\n",
    "print(\"√âtape 2 : Initialisation...\")\n",
    "try:\n",
    "    # Initialiser avec TON projet\n",
    "    ee.Initialize(project=TON_PROJET)\n",
    "    print(\"‚úì SUCC√àS ! Google Earth Engine est initialis√©\")\n",
    "    print(f\"‚úì Projet utilis√© : {TON_PROJET}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó ERREUR : {e}\")\n",
    "    print(\"\\nEssayons sans sp√©cifier de projet...\")\n",
    "    try:\n",
    "        ee.Initialize()\n",
    "        print(\"‚úì SUCC√àS avec initialisation simple !\")\n",
    "    except Exception as e2:\n",
    "        print(f\"‚úó √âchec aussi : {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9c36a83-65af-40a2-b75a-d0895f883014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARGEMENT DE TES DONN√âES GADM DEPUIS TON ASSET\n",
      "======================================================================\n",
      "Asset ID utilis√© : projects/earthengine-legacy/assets/GADM/gadm41_SEN_2\n",
      "‚ùå ERREUR : Collection.loadTable: Name \"projects/earthengine-legacy/assets/GADM/gadm41_SEN_2\" is invalid.  Legacy assets under \"projects/earthengine-legacy/assets/**\" must have the top-level folders \"users\" or \"projects\" (e.g., \"projects/earthengine-legacy/assets/users/foo/bar\") and public assets must start with \"projects/earthengine-public/\n",
      "\n",
      "Probl√®mes possibles :\n",
      "1. Asset ID incorrect\n",
      "2. Shapefile pas encore compl√®tement upload√©\n",
      "3. Probl√®me de permissions\n",
      "\n",
      "On utilise FAO GAUL en attendant...\n",
      "‚úì 43 d√©partements (FAO temporaire)\n"
     ]
    }
   ],
   "source": [
    "# Cellule 4 : CHARGEMENT DE TES DONN√âES GADM\n",
    "print(\"CHARGEMENT DE TES DONN√âES GADM DEPUIS TON ASSET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import ee\n",
    "\n",
    "# TON Asset ID exact\n",
    "TON_ASSET_ID = \"projects/earthengine-legacy/assets/GADM/gadm41_SEN_2\"\n",
    "print(f\"Asset ID utilis√© : {TON_ASSET_ID}\")\n",
    "\n",
    "try:\n",
    "    # Charger TES donn√©es\n",
    "    senegal_gadm = ee.FeatureCollection(TON_ASSET_ID)\n",
    "    \n",
    "    # Compter les d√©partements\n",
    "    nb_depts = senegal_gadm.size().getInfo()\n",
    "    print(f\"‚úÖ SUCC√àS ! {nb_depts} d√©partements charg√©s\")\n",
    "    \n",
    "    # Afficher les propri√©t√©s du premier d√©partement\n",
    "    premier = senegal_gadm.first()\n",
    "    props = premier.getInfo()['properties']\n",
    "    \n",
    "    print(f\"\\nPropri√©t√©s disponibles (10 premi√®res) :\")\n",
    "    for i, (cle, valeur) in enumerate(list(props.items())[:10]):\n",
    "        print(f\"  {i+1:2d}. {cle:20} : {str(valeur)[:30]}...\")\n",
    "    \n",
    "    # Chercher le nom du d√©partement\n",
    "    noms_possibles = ['NAME_2', 'name_2', 'NOM', 'nom', 'NAME', 'ADM2_NAME', 'adm2_name']\n",
    "    nom_colonne = None\n",
    "    \n",
    "    for nom in noms_possibles:\n",
    "        if nom in props:\n",
    "            nom_colonne = nom\n",
    "            break\n",
    "    \n",
    "    if nom_colonne:\n",
    "        print(f\"\\n‚úÖ Colonne pour les noms : '{nom_colonne}'\")\n",
    "        \n",
    "        # Afficher 5 premiers d√©partements\n",
    "        print(\"\\n5 premiers d√©partements :\")\n",
    "        depts = senegal_gadm.toList(5).getInfo()\n",
    "        \n",
    "        for i, dept in enumerate(depts):\n",
    "            nom = dept['properties'].get(nom_colonne, 'Nom inconnu')\n",
    "            # Chercher aussi la r√©gion\n",
    "            region_cols = ['NAME_1', 'name_1', 'ADM1_NAME', 'REGION']\n",
    "            region = 'R√©gion inconnue'\n",
    "            for reg in region_cols:\n",
    "                if reg in dept['properties']:\n",
    "                    region = dept['properties'][reg]\n",
    "                    break\n",
    "            \n",
    "            print(f\"  {i+1}. {nom:25} ‚Üí R√©gion: {region}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Colonne de noms non trouv√©e\")\n",
    "        print(f\"  Propri√©t√©s disponibles : {list(props.keys())}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ TES DONN√âES GADM SONT PR√äTES POUR L'ANALYSE !\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERREUR : {e}\")\n",
    "    print(\"\\nProbl√®mes possibles :\")\n",
    "    print(\"1. Asset ID incorrect\")\n",
    "    print(\"2. Shapefile pas encore compl√®tement upload√©\")\n",
    "    print(\"3. Probl√®me de permissions\")\n",
    "    print(\"\\nOn utilise FAO GAUL en attendant...\")\n",
    "    \n",
    "    senegal_gadm = ee.FeatureCollection(\"FAO/GAUL/2015/level2\") \\\n",
    "        .filter(ee.Filter.eq('ADM0_NAME', 'Senegal'))\n",
    "    print(f\"‚úì {senegal_gadm.size().getInfo()} d√©partements (FAO temporaire)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75f5efd4-f83e-4677-a332-003f3a01a694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Google Earth Engine initialis√©\n",
      "\n",
      " P√©riode d'analyse : 2018-01-01 √† 2018-12-31\n",
      " Seuil fixe : NDBI > 0\n",
      " Masque SCL unifi√© : Classes 4, 6, 7\n",
      "   ‚Ä¢ 4: V√©g√©tation\n",
      "   ‚Ä¢ 6: Eau\n",
      "   ‚Ä¢ 7: Non classifi√© (inclut potentiellement zones urbaines)\n",
      "\n",
      "üîç Chargement des images Sentinel-2...\n",
      "   Nombre total d'images : 375\n",
      "\n",
      "üìä Analyse de tous les d√©partements avec masque 4,6,7...\n",
      "   Nombre total de d√©partements : 45\n",
      "   [1/45] Dagana (Saint-Louis)...\n",
      "     ‚Üí 33.4% de zones b√¢ties\n",
      "       NDBI moyen: -0.110, Images: 27\n",
      "   [2/45] Podor (Saint-Louis)...\n",
      "     ‚Üí 35.1% de zones b√¢ties\n",
      "       NDBI moyen: -0.086, Images: 52\n",
      "   [3/45] Saint-Louis (Saint-Louis)...\n",
      "     ‚Üí 76.6% de zones b√¢ties\n",
      "       NDBI moyen: 0.073, Images: 1\n",
      "   [4/45] Bounkiling (S√©dhiou)...\n",
      "     ‚Üí 46.9% de zones b√¢ties\n",
      "       NDBI moyen: -0.012, Images: 17\n",
      "   [5/45] Goudomp (S√©dhiou)...\n",
      "     ‚Üí 16.1% de zones b√¢ties\n",
      "       NDBI moyen: -0.091, Images: 29\n",
      "   [6/45] S√©dhiou (S√©dhiou)...\n",
      "     ‚Üí 19.6% de zones b√¢ties\n",
      "       NDBI moyen: -0.058, Images: 29\n",
      "   [7/45] Bakel (Tambacounda)...\n",
      "     ‚Üí 67.4% de zones b√¢ties\n",
      "       NDBI moyen: 0.030, Images: 52\n",
      "   [8/45] Goudiry (Tambacounda)...\n",
      "     ‚Üí 59.6% de zones b√¢ties\n",
      "       NDBI moyen: -0.007, Images: 75\n",
      "   [9/45] Koupentoum (Tambacounda)...\n",
      "     ‚Üí 32.6% de zones b√¢ties\n",
      "       NDBI moyen: -0.051, Images: 29\n",
      "   [10/45] Tambacounda (Tambacounda)...\n",
      "     ‚Üí 34.4% de zones b√¢ties\n",
      "       NDBI moyen: -0.052, Images: 101\n",
      "   [11/45] Mbour (Thi√®s)...\n",
      "     ‚Üí 56.3% de zones b√¢ties\n",
      "       NDBI moyen: -0.038, Images: 14\n",
      "   [12/45] Thi√®s (Thi√®s)...\n",
      "     ‚Üí 82.2% de zones b√¢ties\n",
      "       NDBI moyen: 0.042, Images: 5\n",
      "   [13/45] Tivaouane (Thi√®s)...\n",
      "     ‚Üí 86.4% de zones b√¢ties\n",
      "       NDBI moyen: 0.060, Images: 8\n",
      "   [14/45] Bignona (Ziguinchor)...\n",
      "     ‚Üí 13.8% de zones b√¢ties\n",
      "       NDBI moyen: -0.150, Images: 42\n",
      "   [15/45] Oussouye (Ziguinchor)...\n",
      "     ‚Üí 9.6% de zones b√¢ties\n",
      "       NDBI moyen: -0.263, Images: 19\n",
      "   [16/45] Ziguinchor (Ziguinchor)...\n",
      "     ‚Üí 6.3% de zones b√¢ties\n",
      "       NDBI moyen: -0.197, Images: 27\n",
      "   [17/45] Dakar (Dakar)...\n",
      "     ‚Üí 81.6% de zones b√¢ties\n",
      "       NDBI moyen: 0.069, Images: 2\n",
      "   [18/45] Gu√©diawaye (Dakar)...\n",
      "     ‚Üí 76.2% de zones b√¢ties\n",
      "       NDBI moyen: 0.127, Images: 2\n",
      "   [19/45] Pikine (Dakar)...\n",
      "     ‚Üí 71.2% de zones b√¢ties\n",
      "       NDBI moyen: 0.111, Images: 2\n",
      "   [20/45] Rufisque (Dakar)...\n",
      "     ‚Üí 62.4% de zones b√¢ties\n",
      "       NDBI moyen: 0.042, Images: 2\n",
      "   [21/45] Bambey (Diourbel)...\n",
      "     ‚Üí 93.0% de zones b√¢ties\n",
      "       NDBI moyen: 0.074, Images: 4\n",
      "   [22/45] Diourbel (Diourbel)...\n",
      "     ‚Üí 94.5% de zones b√¢ties\n",
      "       NDBI moyen: 0.076, Images: 4\n",
      "        Diagnostic: URBAIN_SECONDAIRE_ELEVE\n",
      "   [23/45] Mback√© (Diourbel)...\n",
      "     ‚Üí 24.4% de zones b√¢ties\n",
      "       NDBI moyen: -0.071, Images: 26\n",
      "   [24/45] Fatick (Fatick)...\n",
      "     ‚Üí 29.0% de zones b√¢ties\n",
      "       NDBI moyen: -0.141, Images: 14\n",
      "   [25/45] Foundiougne (Fatick)...\n",
      "     ‚Üí 11.8% de zones b√¢ties\n",
      "       NDBI moyen: -0.231, Images: 13\n",
      "   [26/45] Gossas (Fatick)...\n",
      "     ‚Üí 24.4% de zones b√¢ties\n",
      "       NDBI moyen: -0.064, Images: 46\n",
      "   [27/45] Birkilane (Kaffrine)...\n",
      "     ‚Üí 83.5% de zones b√¢ties\n",
      "       NDBI moyen: 0.066, Images: 19\n",
      "   [28/45] Kaffrine (Kaffrine)...\n",
      "     ‚Üí 45.1% de zones b√¢ties\n",
      "       NDBI moyen: -0.029, Images: 13\n",
      "   [29/45] Koungheul (Kaffrine)...\n",
      "     ‚Üí 17.0% de zones b√¢ties\n",
      "       NDBI moyen: -0.093, Images: 27\n",
      "   [30/45] Mal√®me Hodar (Kaffrine)...\n",
      "     ‚Üí 19.1% de zones b√¢ties\n",
      "       NDBI moyen: -0.090, Images: 13\n",
      "   [31/45] Guinguin√©o (Kaolack)...\n",
      "     ‚Üí 58.2% de zones b√¢ties\n",
      "       NDBI moyen: 0.004, Images: 46\n",
      "   [32/45] Kaolack (Kaolack)...\n",
      "     ‚Üí 66.5% de zones b√¢ties\n",
      "       NDBI moyen: 0.011, Images: 20\n",
      "   [33/45] Nioro du Rip (Kaolack)...\n",
      "     ‚Üí 64.2% de zones b√¢ties\n",
      "       NDBI moyen: -0.025, Images: 19\n",
      "   [34/45] K√©dougou (K√©dougou)...\n",
      "     ‚Üí 43.0% de zones b√¢ties\n",
      "       NDBI moyen: -0.018, Images: 57\n",
      "   [35/45] Sal√©mata (K√©dougou)...\n",
      "     ‚Üí 43.4% de zones b√¢ties\n",
      "       NDBI moyen: -0.017, Images: 36\n",
      "   [36/45] Saraya (K√©dougou)...\n",
      "     ‚Üí 46.6% de zones b√¢ties\n",
      "       NDBI moyen: -0.007, Images: 77\n",
      "   [37/45] Kolda (Kolda)...\n",
      "     ‚Üí 8.8% de zones b√¢ties\n",
      "       NDBI moyen: -0.093, Images: 17\n",
      "   [38/45] M√©dina Yoro Foula (Kolda)...\n",
      "     ‚Üí 21.7% de zones b√¢ties\n",
      "       NDBI moyen: -0.061, Images: 27\n",
      "   [39/45] V√©lingara (Kolda)...\n",
      "     ‚Üí 11.0% de zones b√¢ties\n",
      "       NDBI moyen: -0.093, Images: 31\n",
      "   [40/45] K√©b√©mer (Louga)...\n",
      "     ‚Üí 27.5% de zones b√¢ties\n",
      "       NDBI moyen: -0.093, Images: 36\n",
      "   [41/45] Lingu√®re (Louga)...\n",
      "     ‚Üí 25.3% de zones b√¢ties\n",
      "       NDBI moyen: -0.083, Images: 52\n",
      "   [42/45] Louga (Louga)...\n",
      "     ‚Üí 48.7% de zones b√¢ties\n",
      "       NDBI moyen: -0.033, Images: 34\n",
      "   [43/45] Kanel (Matam)...\n",
      "     ‚Üí 56.1% de zones b√¢ties\n",
      "       NDBI moyen: -0.013, Images: 68\n",
      "   [44/45] Matam (Matam)...\n",
      "     ‚Üí 24.7% de zones b√¢ties\n",
      "       NDBI moyen: -0.129, Images: 24\n",
      "   [45/45] Ran√©rou Ferlo (Matam)...\n",
      "     ‚Üí 64.1% de zones b√¢ties\n",
      "       NDBI moyen: 0.020, Images: 33\n",
      " ANALYSE DES R√âSULTATS FINAUX\n",
      "\n",
      "üìä DISTRIBUTION DES R√âSULTATS :\n",
      "   % B√¢ti moyen : 44.9%\n",
      "   M√©diane : 43.4%\n",
      "   Minimum : 6.3%\n",
      "   Maximum : 94.5%\n",
      "   √âcart-type : 25.9%\n",
      "\n",
      " TOP 20 D√âPARTEMENTS LES PLUS URBANIS√âS :\n",
      "    1. Diourbel             :   94.5% ‚ö†Ô∏èURBAIN_SECONDAIRE_ELEVE\n",
      "    2. Bambey               :   93.0%\n",
      "    3. Tivaouane            :   86.4%\n",
      "    4. Birkilane            :   83.5%\n",
      "    5. Thi√®s                :   82.2%\n",
      "    6. Dakar                :   81.6%\n",
      "    7. Saint-Louis          :   76.6%\n",
      "    8. Gu√©diawaye           :   76.2%\n",
      "    9. Pikine               :   71.2%\n",
      "   10. Bakel                :   67.4%\n",
      "   11. Kaolack              :   66.5%\n",
      "   12. Nioro du Rip         :   64.2%\n",
      "   13. Ran√©rou Ferlo        :   64.1%\n",
      "   14. Rufisque             :   62.4%\n",
      "   15. Goudiry              :   59.6%\n",
      "   16. Guinguin√©o           :   58.2%\n",
      "   17. Mbour                :   56.3%\n",
      "   18. Kanel                :   56.1%\n",
      "   19. Louga                :   48.7%\n",
      "   20. Bounkiling           :   46.9%\n",
      "\n",
      " ANALYSE PAR R√âGION :\n",
      "   Thi√®s           :  75.0% (min:56.3%, max: 86.4%, 3 depts)\n",
      "   Dakar           :  72.8% (min:62.4%, max: 81.6%, 4 depts)\n",
      "   Diourbel        :  70.6% (min:24.4%, max: 94.5%, 3 depts)\n",
      "   Kaolack         :  63.0% (min:58.2%, max: 66.5%, 3 depts)\n",
      "   Tambacounda     :  48.5% (min:32.6%, max: 67.4%, 4 depts)\n",
      "   Saint-Louis     :  48.4% (min:33.4%, max: 76.6%, 3 depts)\n",
      "   Matam           :  48.3% (min:24.7%, max: 64.1%, 3 depts)\n",
      "   K√©dougou        :  44.3% (min:43.0%, max: 46.6%, 3 depts)\n",
      "   Kaffrine        :  41.2% (min:17.0%, max: 83.5%, 4 depts)\n",
      "   Louga           :  33.8% (min:25.3%, max: 48.7%, 3 depts)\n",
      "   S√©dhiou         :  27.5% (min:16.1%, max: 46.9%, 3 depts)\n",
      "   Fatick          :  21.7% (min:11.8%, max: 29.0%, 3 depts)\n",
      "   Kolda           :  13.8% (min: 8.8%, max: 21.7%, 3 depts)\n",
      "   Ziguinchor      :   9.9% (min: 6.3%, max: 13.8%, 3 depts)\n",
      "\n",
      " Sauvegarde des r√©sultats...\n",
      " Fichier complet sauvegard√© : senegal_unifie_467_20251222_215622.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SCRIPT UNIFIE - Tous les d√©partements avec masque SCL 4, 6, 7\n",
    "Masque commun : v√©g√©tation + eau + non classifi√©\n",
    "Seuil fixe : NDBI > 0\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================\n",
    "# 1. INITIALISATION\n",
    "# ============================================\n",
    "\n",
    "try:\n",
    "    ee.Initialize()\n",
    "    print(\" Google Earth Engine initialis√©\")\n",
    "except Exception as e:\n",
    "    print(\" Erreur d'initialisation :\", e)\n",
    "    raise\n",
    "\n",
    "# Configuration\n",
    "ASSET_GADM = \"projects/userscheikhthioub501/assets/gadm41_SEN_2\"\n",
    "ANNEE = 2018\n",
    "\n",
    "print(f\"\\n P√©riode d'analyse : {ANNEE}-01-01 √† {ANNEE}-12-31\")\n",
    "print(f\" Seuil fixe : NDBI > 0\")\n",
    "print(f\" Masque SCL unifi√© : Classes 4, 6, 7\")\n",
    "print(\"   ‚Ä¢ 4: V√©g√©tation\")\n",
    "print(\"   ‚Ä¢ 6: Eau\")\n",
    "print(\"   ‚Ä¢ 7: Non classifi√© (inclut potentiellement zones urbaines)\")\n",
    "\n",
    "# ============================================\n",
    "# 2. FONCTION DE MASQUAGE UNIFIE\n",
    "# ============================================\n",
    "\n",
    "def masquer_uniforme_467(image):\n",
    "    \"\"\"\n",
    "    Masque unifi√© pour TOUS les d√©partements\n",
    "    Classes SCL : 4 (v√©g√©tation), 6 (eau), 7 (non classifi√©)\n",
    "    \"\"\"\n",
    "    scl = image.select('SCL')\n",
    "    \n",
    "    # Masque : seulement 4, 6, 7\n",
    "    masque_valide = scl.eq(4).Or(scl.eq(6)).Or(scl.eq(7))\n",
    "    \n",
    "    # Appliquer le masque\n",
    "    image_masquee = image.updateMask(masque_valide)\n",
    "    \n",
    "    # Normaliser les r√©flectances (toujours diviser par 10000)\n",
    "    bands = ['B2', 'B3', 'B4', 'B8', 'B11']\n",
    "    return image_masquee.select(bands).divide(10000)\n",
    "\n",
    "# ============================================\n",
    "# 3. CHARGEMENT ET PR√âPARATION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüîç Chargement des images Sentinel-2...\")\n",
    "\n",
    "# Collection pour toute l'ann√©e\n",
    "collection_s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "    .filterBounds(ee.FeatureCollection(ASSET_GADM)) \\\n",
    "    .filterDate(f'{ANNEE}-01-01', f'{ANNEE}-12-31') \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 50))\n",
    "\n",
    "nombre_images_total = collection_s2.size().getInfo()\n",
    "print(f\"   Nombre total d'images : {nombre_images_total}\")\n",
    "\n",
    "# ============================================\n",
    "# 4. ANALYSE PAR D√âPARTEMENT\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüìä Analyse de tous les d√©partements avec masque 4,6,7...\")\n",
    "\n",
    "senegal = ee.FeatureCollection(ASSET_GADM)\n",
    "features = senegal.toList(senegal.size()).getInfo()\n",
    "\n",
    "\n",
    "\n",
    "print(f\"   Nombre total de d√©partements : {len(features)}\")\n",
    "\n",
    "resultats = []\n",
    "\n",
    "for i, feat in enumerate(features):\n",
    "    try:\n",
    "        feature = ee.Feature(feat)\n",
    "        geom = feature.geometry()\n",
    "        props = feat['properties']\n",
    "        \n",
    "        nom_dept = props.get('NAME_2', f'Dept_{i}')\n",
    "        nom_region = props.get('NAME_1', '')\n",
    "        \n",
    "        print(f\"   [{i+1}/{len(features)}] {nom_dept} ({nom_region})...\")\n",
    "        \n",
    "        # ====================================\n",
    "        # √âTAPE 1 : Cr√©ation du composite d√©partemental\n",
    "        # ====================================\n",
    "        \n",
    "        collection_dept = collection_s2 \\\n",
    "            .filterBounds(geom) \\\n",
    "            .map(masquer_uniforme_467)\n",
    "        \n",
    "        n_images = collection_dept.size().getInfo()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if n_images > 0:\n",
    "            # ====================================\n",
    "            # √âTAPE 2 : Cr√©ation du composite (MOYENNE)\n",
    "            # ====================================\n",
    "            composite = collection_dept.mean().clip(geom)\n",
    "            \n",
    "            # ====================================\n",
    "            # √âTAPE 3 : Calcul du NDBI\n",
    "            # ====================================\n",
    "            ndbi = composite.normalizedDifference(['B11', 'B8']).rename('NDBI')\n",
    "            \n",
    "            # Calcul du NDBI moyen (pour information)\n",
    "            stats_ndbi = ndbi.reduceRegion(\n",
    "                reducer=ee.Reducer.mean(),\n",
    "                geometry=geom,\n",
    "                scale=30,\n",
    "                maxPixels=1e9,\n",
    "                bestEffort=True\n",
    "            ).getInfo()\n",
    "            \n",
    "            ndbi_moyen = stats_ndbi.get('NDBI', 0) or 0\n",
    "            \n",
    "            # ====================================\n",
    "            # √âTAPE 4 : Classification avec seuil NDBI > 0\n",
    "            # ====================================\n",
    "            seuil = 0\n",
    "            zones_baties = ndbi.gt(seuil).rename('bati')\n",
    "            \n",
    "            # Calcul du pourcentage de zones b√¢ties\n",
    "            stats_bati = zones_baties.reduceRegion(\n",
    "                reducer=ee.Reducer.mean(),\n",
    "                geometry=geom,\n",
    "                scale=30,\n",
    "                maxPixels=1e9,\n",
    "                bestEffort=True\n",
    "            ).getInfo()\n",
    "            \n",
    "            pct_bati = (stats_bati.get('bati', 0) or 0) * 100\n",
    "            \n",
    "            # ====================================\n",
    "            # √âTAPE 5 : Diagnostic et validation\n",
    "            # ====================================\n",
    "            \n",
    "            # Diagnostic bas√© sur le type de d√©partement\n",
    "            diagnostic = \"OK\"\n",
    "            \n",
    "            # D√©partements urbains majeurs\n",
    "            depts_urbains_majeurs = ['Dakar', 'Pikine', 'Gu√©diawaye', 'Rufisque', 'Thi√®s', 'Saint-Louis']\n",
    "            if nom_dept in depts_urbains_majeurs:\n",
    "                if pct_bati < 5:\n",
    "                    diagnostic = \"URBAIN_TROP_FAIBLE\"\n",
    "                elif pct_bati > 90:\n",
    "                    diagnostic = \"URBAIN_TROP_ELEVE\"\n",
    "            \n",
    "            # D√©partements urbains secondaires\n",
    "            depts_urbains_secondaires = ['Mbour', 'Mback√©', 'Diourbel', 'Kaolack', 'Ziguinchor']\n",
    "            if nom_dept in depts_urbains_secondaires:\n",
    "                if pct_bati < 2:\n",
    "                    diagnostic = \"URBAIN_SECONDAIRE_FAIBLE\"\n",
    "                elif pct_bati > 80:\n",
    "                    diagnostic = \"URBAIN_SECONDAIRE_ELEVE\"\n",
    "            \n",
    "            # Diagnostic g√©n√©ral\n",
    "            if pct_bati < 0.1:\n",
    "                diagnostic = \"TRES_FAIBLE\"\n",
    "            elif pct_bati > 95:\n",
    "                diagnostic = \"TRES_ELEVE\"\n",
    "            \n",
    "            print(f\"     ‚Üí {pct_bati:.1f}% de zones b√¢ties\")\n",
    "            print(f\"       NDBI moyen: {ndbi_moyen:.3f}, Images: {n_images}\")\n",
    "            \n",
    "            if diagnostic != \"OK\":\n",
    "                print(f\"        Diagnostic: {diagnostic}\")\n",
    "            \n",
    "        else:\n",
    "            pct_bati = -1\n",
    "            ndbi_moyen = -999\n",
    "            diagnostic = \"PAS_D_IMAGES\"\n",
    "            print(f\"      Aucune image disponible m√™me apr√®s relaxation\")\n",
    "        \n",
    "        # ====================================\n",
    "        # √âTAPE 6 : Enregistrement des r√©sultats\n",
    "        # ====================================\n",
    "        \n",
    "        resultat = {\n",
    "            'CODE_REGION': props.get('GID_1', ''),\n",
    "            'NOM_REGION': nom_region,\n",
    "            'CODE_DEPT': props.get('GID_2', ''),\n",
    "            'NOM_DEPT': nom_dept,\n",
    "            'PCT_BATI': pct_bati,\n",
    "            'NDBI_MOYEN': ndbi_moyen,\n",
    "            'SEUIL_NDBI': 0,\n",
    "            'IMAGES_DISPONIBLES': n_images,\n",
    "            'DIAGNOSTIC': diagnostic,\n",
    "            'STRATEGIE': 'UNIFORME_4_6_7',\n",
    "            'PERIODE': f'{ANNEE}-01-01_{ANNEE}-12-31',\n",
    "            'MASQUE_SCL': '4,6,7',\n",
    "            'METHODE_COMPOSITE': 'MOYENNE',\n",
    "            'DATE_TRAITEMENT': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        \n",
    "        resultats.append(resultat)\n",
    "        \n",
    "        # Petite pause pour √©viter les limites\n",
    "        time.sleep(0.05)\n",
    "        \n",
    "    except Exception as e:\n",
    "        nom_dept = props.get('NAME_2', f'Dept_{i}') if 'props' in locals() else f'Dept_{i}'\n",
    "        error_msg = str(e)[:100]\n",
    "        print(f\" Erreur sur {nom_dept}: {error_msg}\")\n",
    "        \n",
    "        resultats.append({\n",
    "            'CODE_REGION': props.get('GID_1', '') if 'props' in locals() else '',\n",
    "            'NOM_REGION': props.get('NAME_1', '') if 'props' in locals() else '',\n",
    "            'CODE_DEPT': props.get('GID_2', '') if 'props' in locals() else '',\n",
    "            'NOM_DEPT': nom_dept,\n",
    "            'PCT_BATI': -1,\n",
    "            'NDBI_MOYEN': -999,\n",
    "            'SEUIL_NDBI': 0,\n",
    "            'IMAGES_DISPONIBLES': 0,\n",
    "            'DIAGNOSTIC': 'ERREUR',\n",
    "            'STRATEGIE': 'UNIFORME_4_6_7',\n",
    "            'PERIODE': f'{ANNEE}-01-01_{ANNEE}-12-31',\n",
    "            'MASQUE_SCL': '4,6,7',\n",
    "            'METHODE_COMPOSITE': 'MOYENNE',\n",
    "            'DATE_TRAITEMENT': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        })\n",
    "        continue\n",
    "\n",
    "# ============================================\n",
    "# 5. ANALYSE DES R√âSULTATS\n",
    "# ============================================\n",
    "\n",
    "\n",
    "print(\" ANALYSE DES R√âSULTATS FINAUX\")\n",
    "\n",
    "df = pd.DataFrame(resultats)\n",
    "\n",
    "\n",
    "if len(df) > 0:\n",
    "    print(f\"\\nüìä DISTRIBUTION DES R√âSULTATS :\")\n",
    "    print(f\"   % B√¢ti moyen : {df['PCT_BATI'].mean():.1f}%\")\n",
    "    print(f\"   M√©diane : {df['PCT_BATI'].median():.1f}%\")\n",
    "    print(f\"   Minimum : {df['PCT_BATI'].min():.1f}%\")\n",
    "    print(f\"   Maximum : {df['PCT_BATI'].max():.1f}%\")\n",
    "    print(f\"   √âcart-type : {df['PCT_BATI'].std():.1f}%\")\n",
    "    \n",
    "   \n",
    "  \n",
    "    \n",
    "    # Top 20 urbanis√©s\n",
    "    print(f\"\\n TOP 20 D√âPARTEMENTS LES PLUS URBANIS√âS :\")\n",
    "    top_20 = df.sort_values('PCT_BATI', ascending=False).head(20)\n",
    "    for i, (_, row) in enumerate(top_20.iterrows(), 1):\n",
    "        diag_indicator = \"\" if row['DIAGNOSTIC'] == 'OK' else f\" ‚ö†Ô∏è{row['DIAGNOSTIC']}\"\n",
    "        print(f\"   {i:2}. {row['NOM_DEPT']:20} : {row['PCT_BATI']:6.1f}%{diag_indicator}\")\n",
    "    \n",
    "    # Analyse par r√©gion\n",
    "    print(f\"\\n ANALYSE PAR R√âGION :\")\n",
    "    regions_stats = df.groupby('NOM_REGION').agg({\n",
    "        'PCT_BATI': ['mean', 'count', 'min', 'max'],\n",
    "        'NOM_DEPT': 'first'\n",
    "    }).round(1)\n",
    "    \n",
    "    regions_stats.columns = ['MOYENNE', 'NB_DEPTS', 'MIN', 'MAX', 'REGION']\n",
    "    \n",
    "    # Trier par % b√¢ti moyen d√©croissant\n",
    "    regions_stats = regions_stats.sort_values('MOYENNE', ascending=False)\n",
    "    \n",
    "    for region, data in regions_stats.iterrows():\n",
    "        print(f\"   {region:15} : {data['MOYENNE']:5.1f}% (min:{data['MIN']:4.1f}%, max:{data['MAX']:5.1f}%, {int(data['NB_DEPTS'])} depts)\")\n",
    "\n",
    "# ============================================\n",
    "# 6. SAUVEGARDE ET EXPORT\n",
    "# ============================================\n",
    "\n",
    "print(f\"\\n Sauvegarde des r√©sultats...\")\n",
    "\n",
    "# Nom du fichier avec timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "fichier_resultats = f\"senegal_unifie_467_{timestamp}.csv\"\n",
    "df.to_csv(fichier_resultats, index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "print(f\" Fichier complet sauvegard√© : {fichier_resultats}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db958fc4-bfac-4087-b2a9-23db23b7938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VISUALISATION URBANISATION S√âN√âGAL 2018\n",
      "======================================================================\n",
      "======================================================================\n",
      "CHARGEMENT DES DONN√âES\n",
      "======================================================================\n",
      "üìÇ V√©rification des fichiers...\n",
      "  - CSV: C:\\Users\\HP\\Documents\\ISEP3\\Semestre 1_CT\\Stat\\Stat_Spatiale\\TP6\\data\\senegal_unifie_467_20251222_141659.csv\n",
      "    Existe: ‚úì\n",
      "  - Shapefile r√©gions: C:\\Users\\HP\\Documents\\ISEP3\\Semestre 1_CT\\Stat\\Stat_Spatiale\\TP6\\data\\GADM\\gadm\\gadm41_SEN_shp\\gadm41_SEN_1.shp\n",
      "    Existe: ‚úì\n",
      "  - Shapefile d√©partements: C:\\Users\\HP\\Documents\\ISEP3\\Semestre 1_CT\\Stat\\Stat_Spatiale\\TP6\\data\\GADM\\gadm\\gadm41_SEN_shp\\gadm41_SEN_2.shp\n",
      "    Existe: ‚úì\n",
      "\n",
      "üìä Chargement CSV...\n",
      "‚úì 45 d√©partements, 45 valides\n",
      "\n",
      "üó∫Ô∏è  Chargement shapefiles GADM...\n",
      "‚úì 45 d√©partements, 14 r√©gions\n",
      "‚úì Dossier sortie: C:\\Users\\HP\\Documents\\ISEP3\\Semestre 1_CT\\Stat\\Stat_Spatiale\\TP6\\visualisations\n",
      "\n",
      "======================================================================\n",
      "üìä STATISTIQUES DESCRIPTIVES\n",
      "======================================================================\n",
      "\n",
      "Moyenne: 44.87% | M√©diane: 43.40%\n",
      "Min: 6.29% | Max: 94.52%\n",
      "√âcart-type: 25.89%\n",
      "\n",
      "======================================================================\n",
      "G√âN√âRATION DES VISUALISATIONS\n",
      "======================================================================\n",
      "\n",
      "‚úì 01_distribution.png\n",
      "‚úì 02_top_departements.png\n",
      "‚úì 03_analyse_regions.png\n",
      "\n",
      "üìç D√©partements match√©s: 45/45 (100.0%)\n",
      "‚úì 04_carte_departements.png\n",
      "üìç R√©gions match√©es: 14/14 (100.0%)\n",
      "‚úì 05_carte_regions.png\n",
      "‚úì 06_carte_categories.png\n",
      "\n",
      "======================================================================\n",
      "‚úÖ VISUALISATIONS TERMIN√âES\n",
      "======================================================================\n",
      "\n",
      "üìÇ Fichiers dans: C:\\Users\\HP\\Documents\\ISEP3\\Semestre 1_CT\\Stat\\Stat_Spatiale\\TP6\\visualisations\n",
      "\n",
      "üìã Fichiers g√©n√©r√©s:\n",
      "  1. 01_distribution.png - Distribution globale\n",
      "  2. 02_top_departements.png - Top/Bottom 20\n",
      "  3. 03_analyse_regions.png - Analyse r√©gionale\n",
      "  4. 04_carte_departements.png - Carte d√©partements\n",
      "  5. 05_carte_regions.png - Carte r√©gions\n",
      "  6. 06_carte_categories.png - Carte cat√©gories\n",
      "\n",
      "‚ú® Analyse termin√©e avec succ√®s!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SCRIPT COMPLET - Visualisation Urbanisation S√©n√©gal avec Cartes GADM\n",
    "Auteur: Analyse Spatiale TP6\n",
    "Date: D√©cembre 2024\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import unicodedata\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "# ============================================\n",
    "# CHEMINS ET CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "REPERTOIRE_BASE = Path(r\"C:\\Users\\HP\\Documents\\ISEP3\\Semestre 1_CT\\Stat\\Stat_Spatiale\\TP6\")\n",
    "CHEMIN_CSV = REPERTOIRE_BASE / \"data\" / \"senegal_unifie_467_20251222_141659.csv\"\n",
    "# CORRECTION 1: Supprimer l'espace apr√®s \"gadm\" -> \"gadm\" pas \"gadm \"\n",
    "CHEMIN_GADM = REPERTOIRE_BASE / \"data\" / \"GADM\" / \"gadm\" / \"gadm41_SEN_shp\"\n",
    "DOSSIER_SORTIE = REPERTOIRE_BASE / \"visualisations\"\n",
    "\n",
    "SHP_REGIONS = CHEMIN_GADM / \"gadm41_SEN_1.shp\"\n",
    "SHP_DEPARTEMENTS = CHEMIN_GADM / \"gadm41_SEN_2.shp\"\n",
    "\n",
    "# ============================================\n",
    "# FONCTIONS UTILITAIRES\n",
    "# ============================================\n",
    "\n",
    "def normaliser_noms(nom):\n",
    "    \"\"\"Normalise les noms pour le matching\"\"\"\n",
    "    nom = str(nom).upper().strip()\n",
    "    nom = ''.join(c for c in unicodedata.normalize('NFD', nom) \n",
    "                  if unicodedata.category(c) != 'Mn')\n",
    "    nom = ''.join(c if c.isalnum() or c.isspace() else ' ' for c in nom)\n",
    "    return ' '.join(nom.split())\n",
    "\n",
    "def charger_donnees():\n",
    "    \"\"\"Charge toutes les donn√©es n√©cessaires\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"CHARGEMENT DES DONN√âES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # CORRECTION 2: Ajouter un test pour v√©rifier que les fichiers existent\n",
    "    print(f\"üìÇ V√©rification des fichiers...\")\n",
    "    print(f\"  - CSV: {CHEMIN_CSV}\")\n",
    "    print(f\"    Existe: {'‚úì' if CHEMIN_CSV.exists() else '‚úó'}\")\n",
    "    print(f\"  - Shapefile r√©gions: {SHP_REGIONS}\")\n",
    "    print(f\"    Existe: {'‚úì' if SHP_REGIONS.exists() else '‚úó'}\")\n",
    "    print(f\"  - Shapefile d√©partements: {SHP_DEPARTEMENTS}\")\n",
    "    print(f\"    Existe: {'‚úì' if SHP_DEPARTEMENTS.exists() else '‚úó'}\")\n",
    "    \n",
    "    if not SHP_REGIONS.exists() or not SHP_DEPARTEMENTS.exists():\n",
    "        print(\"\\n‚ùå ERREUR: Fichiers shapefile non trouv√©s!\")\n",
    "        print(f\"   V√©rifiez que ces fichiers existent:\")\n",
    "        print(f\"   {SHP_REGIONS}\")\n",
    "        print(f\"   {SHP_DEPARTEMENTS}\")\n",
    "        print(\"\\n   Essayez cette correction alternative:\")\n",
    "        print(f\"   CHEMIN_GADM = REPERTOIRE_BASE / 'data' / 'GADM' / 'gadm41_SEN_shp'\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # CSV\n",
    "    print(f\"\\nüìä Chargement CSV...\")\n",
    "    df = pd.read_csv(CHEMIN_CSV, encoding='utf-8-sig')\n",
    "    df = df[df['PCT_BATI'] >= 0].copy()\n",
    "    print(f\"‚úì {len(df)} d√©partements, {len(df)} valides\")\n",
    "    \n",
    "    # Shapefiles\n",
    "    print(f\"\\nüó∫Ô∏è  Chargement shapefiles GADM...\")\n",
    "    gdf_dept = gpd.read_file(SHP_DEPARTEMENTS)\n",
    "    gdf_region = gpd.read_file(SHP_REGIONS)\n",
    "    print(f\"‚úì {len(gdf_dept)} d√©partements, {len(gdf_region)} r√©gions\")\n",
    "    \n",
    "    DOSSIER_SORTIE.mkdir(exist_ok=True)\n",
    "    print(f\"‚úì Dossier sortie: {DOSSIER_SORTIE}\")\n",
    "    \n",
    "    return df, df, gdf_dept, gdf_region\n",
    "\n",
    "# ============================================\n",
    "# GRAPHIQUES STATISTIQUES\n",
    "# ============================================\n",
    "\n",
    "def stats_descriptives(df):\n",
    "    \"\"\"Affiche statistiques\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä STATISTIQUES DESCRIPTIVES\")\n",
    "    print(\"=\"*70)\n",
    "    stats = df['PCT_BATI'].describe()\n",
    "    print(f\"\\nMoyenne: {stats['mean']:.2f}% | M√©diane: {stats['50%']:.2f}%\")\n",
    "    print(f\"Min: {stats['min']:.2f}% | Max: {stats['max']:.2f}%\")\n",
    "    print(f\"√âcart-type: {stats['std']:.2f}%\")\n",
    "\n",
    "def graphique_distribution(df):\n",
    "    \"\"\"Distribution de l'urbanisation\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Distribution Urbanisation - S√©n√©gal 2018', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Histogramme\n",
    "    axes[0,0].hist(df['PCT_BATI'], bins=30, color='steelblue', edgecolor='black')\n",
    "    axes[0,0].axvline(df['PCT_BATI'].mean(), color='red', linestyle='--', \n",
    "                      label=f\"Moy: {df['PCT_BATI'].mean():.1f}%\")\n",
    "    axes[0,0].set_title('Distribution des taux')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(alpha=0.3)\n",
    "    \n",
    "    # Boxplot\n",
    "    axes[0,1].boxplot(df['PCT_BATI'], patch_artist=True)\n",
    "    axes[0,1].set_title('Boxplot')\n",
    "    axes[0,1].grid(alpha=0.3)\n",
    "    \n",
    "    # Cumulative\n",
    "    sorted_data = np.sort(df['PCT_BATI'])\n",
    "    cumulative = np.arange(1, len(sorted_data)+1) / len(sorted_data) * 100\n",
    "    axes[1,0].plot(sorted_data, cumulative, 'b-', linewidth=2)\n",
    "    axes[1,0].set_title('Distribution cumulative')\n",
    "    axes[1,0].grid(alpha=0.3)\n",
    "    \n",
    "    # Cat√©gories\n",
    "    bins = [0, 1, 5, 10, 20, 100]\n",
    "    labels = ['<1%', '1-5%', '5-10%', '10-20%', '>20%']\n",
    "    cats = pd.cut(df['PCT_BATI'], bins=bins, labels=labels)\n",
    "    counts = cats.value_counts().sort_index()\n",
    "    colors = ['#2ecc71', '#f39c12', '#e67e22', '#e74c3c', '#c0392b']\n",
    "    axes[1,1].bar(range(len(counts)), counts.values, color=colors, edgecolor='black')\n",
    "    axes[1,1].set_xticks(range(len(counts)))\n",
    "    axes[1,1].set_xticklabels(labels)\n",
    "    axes[1,1].set_title('Cat√©gories d\\'urbanisation')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(DOSSIER_SORTIE / '01_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úì 01_distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "def graphique_top_departements(df):\n",
    "    \"\"\"Top et Bottom d√©partements\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 10))\n",
    "    fig.suptitle('Classement des D√©partements', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Top 20\n",
    "    top20 = df.nlargest(20, 'PCT_BATI')\n",
    "    y = np.arange(len(top20))\n",
    "    ax1.barh(y, top20['PCT_BATI'], color='steelblue', edgecolor='black')\n",
    "    ax1.set_yticks(y)\n",
    "    ax1.set_yticklabels([f\"{r['NOM_DEPT']}\" for _, r in top20.iterrows()], fontsize=9)\n",
    "    ax1.set_title('Top 20 - Plus urbanis√©s', fontweight='bold')\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.grid(alpha=0.3, axis='x')\n",
    "    \n",
    "    # Bottom 20\n",
    "    bottom20 = df.nsmallest(20, 'PCT_BATI')\n",
    "    y2 = np.arange(len(bottom20))\n",
    "    ax2.barh(y2, bottom20['PCT_BATI'], color='coral', edgecolor='black')\n",
    "    ax2.set_yticks(y2)\n",
    "    ax2.set_yticklabels([f\"{r['NOM_DEPT']}\" for _, r in bottom20.iterrows()], fontsize=9)\n",
    "    ax2.set_title('Bottom 20 - Moins urbanis√©s', fontweight='bold')\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.grid(alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(DOSSIER_SORTIE / '02_top_departements.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úì 02_top_departements.png\")\n",
    "    plt.close()\n",
    "\n",
    "def graphique_regions(df_valides):\n",
    "    \"\"\"Analyse par r√©gion\"\"\"\n",
    "    stats_reg = df_valides.groupby('NOM_REGION')['PCT_BATI'].agg(['mean', 'count']).sort_values('mean', ascending=False)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 10))  # Augment√© la largeur\n",
    "    fig.suptitle('Analyse par R√©gion - S√©n√©gal 2018', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Moyennes avec noms et valeurs\n",
    "    y = np.arange(len(stats_reg))\n",
    "    bars = ax1.barh(y, stats_reg['mean'], color='steelblue', edgecolor='black')\n",
    "    ax1.set_yticks(y)\n",
    "    \n",
    "    # Noms des r√©gions avec statistiques\n",
    "    labels = []\n",
    "    for idx, (region, row) in enumerate(stats_reg.iterrows()):\n",
    "        label = f\"{region}\\n({row['count']} depts, {row['mean']:.1f}%)\"\n",
    "        labels.append(label)\n",
    "    \n",
    "    ax1.set_yticklabels(labels, fontsize=9)\n",
    "    ax1.set_title('Taux moyen d\\'urbanisation par r√©gion', fontweight='bold')\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.grid(alpha=0.3, axis='x')\n",
    "    ax1.set_xlabel('Taux d\\'urbanisation (%)')\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        ax1.text(width + 0.2, bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.1f}%', ha='left', va='center', fontsize=9)\n",
    "    \n",
    "    # Boxplots am√©lior√©s\n",
    "    regions_order = stats_reg.index\n",
    "    data = [df_valides[df_valides['NOM_REGION']==r]['PCT_BATI'].values for r in regions_order]\n",
    "    bp = ax2.boxplot(data, labels=regions_order, patch_artist=True, showmeans=True)\n",
    "    \n",
    "    for patch in bp['boxes']:\n",
    "        patch.set_facecolor('lightblue')\n",
    "    \n",
    "    # Moyennes en rouge\n",
    "    bp['means'][0].set_marker('D')\n",
    "    bp['means'][0].set_markerfacecolor('red')\n",
    "    bp['means'][0].set_markeredgecolor('red')\n",
    "    \n",
    "    ax2.set_xticklabels(regions_order, rotation=45, ha='right', fontsize=8)\n",
    "    ax2.set_title('Distribution des taux par r√©gion', fontweight='bold')\n",
    "    ax2.grid(alpha=0.3, axis='y')\n",
    "    ax2.set_ylabel('Taux d\\'urbanisation (%)')\n",
    "    \n",
    "    # Ajouter l'√©chelle et infos\n",
    "    ax2.text(0.02, 0.98, f'Total: {len(df_valides)} d√©partements',\n",
    "            transform=ax2.transAxes, fontsize=9,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(DOSSIER_SORTIE / '03_analyse_regions.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úì 03_analyse_regions.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    return stats_reg\n",
    "\n",
    "# ============================================\n",
    "# CARTES CHOROPL√àTHES\n",
    "# ============================================\n",
    "# ============================================\n",
    "# CARTES CHOROPL√àTHES AM√âLIOR√âES (sans mapclassify)\n",
    "# ============================================\n",
    "\n",
    "def carte_departements(df_valides, gdf_dept):\n",
    "    \"\"\"Carte d√©partements avec noms et √©chelle\"\"\"\n",
    "    # Normalisation et fusion\n",
    "    df_valides['NOM_NORM'] = df_valides['NOM_DEPT'].apply(normaliser_noms)\n",
    "    gdf_dept['NOM_NORM'] = gdf_dept['NAME_2'].apply(normaliser_noms)\n",
    "    gdf = gdf_dept.merge(df_valides[['NOM_NORM', 'PCT_BATI', 'NDBI_MOYEN', 'NOM_REGION']], \n",
    "                         on='NOM_NORM', how='left')\n",
    "    \n",
    "    matched = gdf['PCT_BATI'].notna().sum()\n",
    "    print(f\"\\nüìç D√©partements match√©s: {matched}/{len(gdf)} ({matched/len(gdf)*100:.1f}%)\")\n",
    "    \n",
    "    # Carte\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 12))\n",
    "    fig.suptitle('ANALYSE SPATIALE DE L\\'URBANISATION - S√âN√âGAL 2018\\nCartographie par D√©partement',\n",
    "                 fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # 1. TAUX D'URBANISATION\n",
    "    # Classification manuelle (quantiles) au lieu de NaturalBreaks\n",
    "    if gdf['PCT_BATI'].notna().sum() > 5:\n",
    "        # Cr√©er 5 classes bas√©es sur les quantiles\n",
    "        pct_data = gdf['PCT_BATI'].dropna()\n",
    "        if len(pct_data) >= 5:\n",
    "            quantiles = np.percentile(pct_data, [0, 20, 40, 60, 80, 100])\n",
    "            # Ajuster les limites pour √©viter les valeurs d√©cimales trop pr√©cises\n",
    "            quantiles = [round(q, 1) for q in quantiles]\n",
    "            labels = [f'{quantiles[i]:.1f}-{quantiles[i+1]:.1f}%' for i in range(len(quantiles)-1)]\n",
    "    \n",
    "    # Carte choropl√®the avec classification\n",
    "    gdf.plot(column='PCT_BATI', cmap='YlOrRd', linewidth=0.8, edgecolor='black', \n",
    "             legend=True, ax=ax1, missing_kwds={'color': 'lightgrey', 'label': 'Donn√©es manquantes'},\n",
    "             legend_kwds={'label': 'Taux d\\'Urbanisation (%)', 'shrink': 0.7, \n",
    "                         'orientation': 'horizontal', 'pad': 0.02})\n",
    "    \n",
    "    # Ajouter noms des d√©partements principaux (top 15 pour √©viter surcharge)\n",
    "    top_depts = df_valides.nlargest(15, 'PCT_BATI')\n",
    "    for _, dept in top_depts.iterrows():\n",
    "        dept_norm = normaliser_noms(dept['NOM_DEPT'])\n",
    "        dept_geom = gdf[gdf['NOM_NORM'] == dept_norm]\n",
    "        if not dept_geom.empty and not dept_geom.geometry.is_empty.all():\n",
    "            centroid = dept_geom.geometry.centroid.iloc[0]\n",
    "            # Nom abr√©g√© si trop long\n",
    "            nom = dept['NOM_DEPT']\n",
    "            if len(nom) > 15:\n",
    "                nom = nom[:12] + '...'\n",
    "            ax1.annotate(f\"{nom}\\n{dept['PCT_BATI']:.1f}%\",\n",
    "                        xy=(centroid.x, centroid.y), xytext=(3, 3),\n",
    "                        textcoords=\"offset points\", fontsize=7, fontweight='bold',\n",
    "                        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax1.set_title('TAUX D\\'URBANISATION PAR D√âPARTEMENT', fontsize=14, fontweight='bold', pad=15)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # √âchelle manuelle (sans matplotlib-scalebar)\n",
    "    bounds = gdf.total_bounds\n",
    "    # Calculer la distance en degr√©s pour 100 km (1 degr√© ‚âà 111 km)\n",
    "    scale_deg = 100 / 111  # Environ 0.9 degr√©s pour 100 km\n",
    "    \n",
    "    # Dessiner une barre d'√©chelle manuellement\n",
    "    scale_x = bounds[0] + (bounds[2] - bounds[0]) * 0.05  # 5% depuis la gauche\n",
    "    scale_y = bounds[1] + (bounds[3] - bounds[1]) * 0.05  # 5% depuis le bas\n",
    "    \n",
    "    ax1.plot([scale_x, scale_x + scale_deg], [scale_y, scale_y], \n",
    "             color='black', linewidth=3)\n",
    "    ax1.plot([scale_x, scale_x], [scale_y-0.05, scale_y+0.05], \n",
    "             color='black', linewidth=2)\n",
    "    ax1.plot([scale_x + scale_deg, scale_x + scale_deg], [scale_y-0.05, scale_y+0.05], \n",
    "             color='black', linewidth=2)\n",
    "    ax1.text(scale_x + scale_deg/2, scale_y - 0.1, '100 km', \n",
    "             ha='center', va='top', fontsize=9, fontweight='bold',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Ajouter fl√®che nord\n",
    "    north_x = bounds[0] + (bounds[2] - bounds[0]) * 0.95\n",
    "    north_y = bounds[1] + (bounds[3] - bounds[1]) * 0.95\n",
    "    ax1.text(north_x, north_y, 'N', fontsize=14, fontweight='bold',\n",
    "             va='center', ha='center', \n",
    "             bbox=dict(boxstyle='circle', facecolor='white', edgecolor='black'))\n",
    "    \n",
    "    # 2. NDBI MOYEN\n",
    "    gdf.plot(column='NDBI_MOYEN', cmap='RdYlGn_r', linewidth=0.8, edgecolor='black',\n",
    "             legend=True, ax=ax2, missing_kwds={'color': 'lightgrey', 'label': 'Donn√©es manquantes'},\n",
    "             legend_kwds={'label': 'NDBI Moyen (Built-up Index)', 'shrink': 0.7,\n",
    "                         'orientation': 'horizontal', 'pad': 0.02})\n",
    "    \n",
    "    # Ajouter noms des r√©gions (centro√Ødes r√©gionaux)\n",
    "    # Dissoudre par r√©gion pour obtenir les polygones r√©gionaux\n",
    "    try:\n",
    "        gdf_regions = gdf.dissolve(by='NOM_REGION')\n",
    "        for idx, region in gdf_regions.iterrows():\n",
    "            if region.geometry.centroid.is_empty:\n",
    "                continue\n",
    "            centroid = region.geometry.centroid\n",
    "            ax2.annotate(idx.upper(), xy=(centroid.x, centroid.y), fontsize=10,\n",
    "                        fontweight='bold', ha='center', va='center',\n",
    "                        bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7))\n",
    "    except:\n",
    "        # Fallback: utiliser les noms des d√©partements de chaque r√©gion\n",
    "        regions = gdf['NOM_REGION'].dropna().unique()\n",
    "        for region in regions:\n",
    "            region_depts = gdf[gdf['NOM_REGION'] == region]\n",
    "            if len(region_depts) > 0:\n",
    "                centroid = region_depts.geometry.centroid.mean()\n",
    "                ax2.annotate(region.upper(), xy=(centroid.x, centroid.y), fontsize=9,\n",
    "                            fontweight='bold', ha='center', va='center',\n",
    "                            bbox=dict(boxstyle='round,pad=0.4', facecolor='yellow', alpha=0.7))\n",
    "    \n",
    "    ax2.set_title('NDBI MOYEN PAR D√âPARTEMENT\\n(Indice de Surface B√¢tie Normalis√©)', \n",
    "                 fontsize=14, fontweight='bold', pad=15)\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # √âchelle manuelle pour ax2\n",
    "    ax2.plot([scale_x, scale_x + scale_deg], [scale_y, scale_y], \n",
    "             color='black', linewidth=3)\n",
    "    ax2.plot([scale_x, scale_x], [scale_y-0.05, scale_y+0.05], \n",
    "             color='black', linewidth=2)\n",
    "    ax2.plot([scale_x + scale_deg, scale_x + scale_deg], [scale_y-0.05, scale_y+0.05], \n",
    "             color='black', linewidth=2)\n",
    "    ax2.text(scale_x + scale_deg/2, scale_y - 0.1, '100 km', \n",
    "             ha='center', va='top', fontsize=9, fontweight='bold',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # L√©gende d'√©chelle commune\n",
    "    fig.text(0.5, 0.02, \n",
    "             f'Source: Donn√©es GADM & Analyse Spatiale 2018 | D√©partements avec donn√©es: {matched}/{len(gdf)} | Projection: WGS84',\n",
    "             ha='center', fontsize=9, style='italic')\n",
    "    \n",
    "    # Statistiques dans un encadr√©\n",
    "    stats_text = f\"\"\"\n",
    "    STATISTIQUES GLOBALES:\n",
    "    ‚Ä¢ Taux moyen: {df_valides['PCT_BATI'].mean():.1f}%\n",
    "    ‚Ä¢ M√©diane: {df_valides['PCT_BATI'].median():.1f}%\n",
    "    ‚Ä¢ √âcart-type: {df_valides['PCT_BATI'].std():.1f}%\n",
    "    ‚Ä¢ Min: {df_valides['PCT_BATI'].min():.1f}%\n",
    "    ‚Ä¢ Max: {df_valides['PCT_BATI'].max():.1f}%\n",
    "    ‚Ä¢ NDBI moyen: {df_valides['NDBI_MOYEN'].mean():.3f}\n",
    "    ‚Ä¢ D√©partements: {len(df_valides)}\n",
    "    \"\"\"\n",
    "    fig.text(0.02, 0.02, stats_text, fontsize=8,\n",
    "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8),\n",
    "             verticalalignment='bottom')\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    plt.savefig(DOSSIER_SORTIE / '04_carte_departements.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úì 04_carte_departements.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def carte_regions(df_valides, gdf_region):\n",
    "    \"\"\"Carte r√©gions avec noms et √©chelle\"\"\"\n",
    "    # Moyennes par r√©gion\n",
    "    reg_moyennes = df_valides.groupby('NOM_REGION').agg({\n",
    "        'PCT_BATI': ['mean', 'std', 'count'],\n",
    "        'NDBI_MOYEN': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    # Aplatir les colonnes\n",
    "    reg_moyennes.columns = ['PCT_MEAN', 'PCT_STD', 'DEPT_COUNT', 'NDBI_MEAN']\n",
    "    reg_moyennes = reg_moyennes.reset_index()\n",
    "    reg_moyennes['NOM_NORM'] = reg_moyennes['NOM_REGION'].apply(normaliser_noms)\n",
    "    \n",
    "    # Fusion\n",
    "    gdf_region['NOM_NORM'] = gdf_region['NAME_1'].apply(normaliser_noms)\n",
    "    gdf = gdf_region.merge(reg_moyennes, on='NOM_NORM', how='left')\n",
    "    \n",
    "    matched = gdf['PCT_MEAN'].notna().sum()\n",
    "    print(f\"üìç R√©gions match√©es: {matched}/{len(gdf)} ({matched/len(gdf)*100:.1f}%)\")\n",
    "    \n",
    "    # Carte\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 12))\n",
    "    fig.suptitle('ANALYSE R√âGIONALE DE L\\'URBANISATION - S√âN√âGAL 2018\\nCartographie par R√©gion Administrative',\n",
    "                 fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # 1. TAUX MOYEN PAR R√âGION\n",
    "    gdf.plot(column='PCT_MEAN', cmap='OrRd', linewidth=1.5, edgecolor='black',\n",
    "             legend=True, ax=ax1, missing_kwds={'color': 'lightgrey', 'label': 'Donn√©es manquantes'},\n",
    "             legend_kwds={'label': 'Taux d\\'Urbanisation Moyen (%)', 'shrink': 0.7,\n",
    "                         'orientation': 'horizontal', 'pad': 0.02})\n",
    "    \n",
    "    # Ajouter noms des r√©gions avec valeurs\n",
    "    for idx, row in gdf.iterrows():\n",
    "        if pd.notna(row['PCT_MEAN']):\n",
    "            centroid = row.geometry.centroid\n",
    "            # Nom de la r√©gion en grand\n",
    "            ax1.annotate(f\"{row['NOM_REGION'].upper()}\", \n",
    "                        xy=(centroid.x, centroid.y), xytext=(0, 12),\n",
    "                        textcoords=\"offset points\", fontsize=11, fontweight='bold',\n",
    "                        ha='center', color='darkblue')\n",
    "            # Valeur en dessous\n",
    "            ax1.annotate(f\"{row['PCT_MEAN']:.1f}% ¬± {row['PCT_STD']:.1f}%\\n({row['DEPT_COUNT']} depts)\",\n",
    "                        xy=(centroid.x, centroid.y), xytext=(0, -12),\n",
    "                        textcoords=\"offset points\", fontsize=9,\n",
    "                        ha='center', va='top',\n",
    "                        bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    ax1.set_title('TAUX MOYEN D\\'URBANISATION PAR R√âGION', fontsize=14, fontweight='bold', pad=15)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # √âchelle manuelle\n",
    "    bounds = gdf.total_bounds\n",
    "    scale_x = bounds[0] + (bounds[2] - bounds[0]) * 0.05\n",
    "    scale_y = bounds[1] + (bounds[3] - bounds[1]) * 0.05\n",
    "    scale_deg = 100 / 111  # 100 km en degr√©s\n",
    "    \n",
    "    ax1.plot([scale_x, scale_x + scale_deg], [scale_y, scale_y], \n",
    "             color='black', linewidth=3)\n",
    "    ax1.plot([scale_x, scale_x], [scale_y-0.05, scale_y+0.05], \n",
    "             color='black', linewidth=2)\n",
    "    ax1.plot([scale_x + scale_deg, scale_x + scale_deg], [scale_y-0.05, scale_y+0.05], \n",
    "             color='black', linewidth=2)\n",
    "    ax1.text(scale_x + scale_deg/2, scale_y - 0.1, '100 km', \n",
    "             ha='center', va='top', fontsize=9, fontweight='bold',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 2. NDBI MOYEN PAR R√âGION\n",
    "    gdf.plot(column='NDBI_MEAN', cmap='RdYlGn', linewidth=1.5, edgecolor='black',\n",
    "             legend=True, ax=ax2, missing_kwds={'color': 'lightgrey', 'label': 'Donn√©es manquantes'},\n",
    "             legend_kwds={'label': 'NDBI Moyen par R√©gion', 'shrink': 0.7,\n",
    "                         'orientation': 'horizontal', 'pad': 0.02})\n",
    "    \n",
    "    # Ajouter valeurs NDBI\n",
    "    for idx, row in gdf.iterrows():\n",
    "        if pd.notna(row['NDBI_MEAN']):\n",
    "            centroid = row.geometry.centroid\n",
    "            ax2.annotate(f\"NDBI: {row['NDBI_MEAN']:.3f}\", \n",
    "                        xy=(centroid.x, centroid.y), fontsize=9, fontweight='bold',\n",
    "                        ha='center', va='center',\n",
    "                        bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    ax2.set_title('NDBI MOYEN PAR R√âGION\\n(Indicateur de Surface B√¢tie)', \n",
    "                 fontsize=14, fontweight='bold', pad=15)\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # √âchelle pour ax2\n",
    "    ax2.plot([scale_x, scale_x + scale_deg], [scale_y, scale_y], \n",
    "             color='black', linewidth=3)\n",
    "    ax2.plot([scale_x, scale_x], [scale_y-0.05, scale_y+0.05], \n",
    "             color='black', linewidth=2)\n",
    "    ax2.plot([scale_x + scale_deg, scale_x + scale_deg], [scale_y-0.05, scale_y+0.05], \n",
    "             color='black', linewidth=2)\n",
    "    ax2.text(scale_x + scale_deg/2, scale_y - 0.1, '100 km', \n",
    "             ha='center', va='top', fontsize=9, fontweight='bold',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Classement des r√©gions\n",
    "    reg_sorted = reg_moyennes.sort_values('PCT_MEAN', ascending=False)\n",
    "    classement_text = \"CLASSEMENT R√âGIONAL:\\n\"\n",
    "    for i, (_, row) in enumerate(reg_sorted.iterrows(), 1):\n",
    "        classement_text += f\"{i}. {row['NOM_REGION']}: {row['PCT_MEAN']:.1f}%\\n\"\n",
    "    \n",
    "    fig.text(0.02, 0.25, classement_text, fontsize=9,\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8),\n",
    "             verticalalignment='top')\n",
    "    \n",
    "    # Statistiques r√©gionales\n",
    "    stats_text = f\"\"\"\n",
    "    STATISTIQUES R√âGIONALES:\n",
    "    ‚Ä¢ R√©gions: {len(reg_moyennes)}\n",
    "    ‚Ä¢ D√©partements totaux: {reg_moyennes['DEPT_COUNT'].sum()}\n",
    "    ‚Ä¢ Taux max: {reg_moyennes['PCT_MEAN'].max():.1f}%\n",
    "    ‚Ä¢ Taux min: {reg_moyennes['PCT_MEAN'].min():.1f}%\n",
    "    ‚Ä¢ √âcart moyen: {reg_moyennes['PCT_STD'].mean():.1f}%\n",
    "    \"\"\"\n",
    "    fig.text(0.02, 0.02, stats_text, fontsize=8,\n",
    "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    # L√©gende\n",
    "    fig.text(0.5, 0.02,\n",
    "             f'Source: Analyse Spatiale 2018 | {len(reg_moyennes)} r√©gions analys√©es | Projection: WGS84',\n",
    "             ha='center', fontsize=9, style='italic')\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    plt.savefig(DOSSIER_SORTIE / '05_carte_regions.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úì 05_carte_regions.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def carte_categories(df_valides, gdf_dept):\n",
    "    \"\"\"Carte cat√©gories d'urbanisation avec √©chelle\"\"\"\n",
    "    # Cat√©gories\n",
    "    df_valides['NOM_NORM'] = df_valides['NOM_DEPT'].apply(normaliser_noms)\n",
    "    bins = [0, 1, 5, 10, 20, 100]\n",
    "    labels = ['Tr√®s faible (<1%)', 'Faible (1-5%)', 'Mod√©r√©e (5-10%)', \n",
    "              '√âlev√©e (10-20%)', 'Tr√®s √©lev√©e (>20%)']\n",
    "    df_valides['CATEGORIE'] = pd.cut(df_valides['PCT_BATI'], bins=bins, labels=labels)\n",
    "    \n",
    "    # Fusion\n",
    "    gdf_dept['NOM_NORM'] = gdf_dept['NAME_2'].apply(normaliser_noms)\n",
    "    gdf = gdf_dept.merge(df_valides[['NOM_NORM', 'CATEGORIE', 'NOM_REGION', 'PCT_BATI']], \n",
    "                         on='NOM_NORM', how='left')\n",
    "    \n",
    "    # Carte\n",
    "    fig, ax = plt.subplots(figsize=(16, 14))\n",
    "    fig.suptitle('CLASSIFICATION DE L\\'URBANISATION - S√âN√âGAL 2018\\nCat√©gories de Taux d\\'Urbanisation par D√©partement',\n",
    "                 fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Palette cat√©gorielle\n",
    "    colors = {\n",
    "        'Tr√®s faible (<1%)': '#2ecc71',      # Vert\n",
    "        'Faible (1-5%)': '#f39c12',         # Orange clair\n",
    "        'Mod√©r√©e (5-10%)': '#e67e22',       # Orange\n",
    "        '√âlev√©e (10-20%)': '#e74c3c',       # Rouge clair\n",
    "        'Tr√®s √©lev√©e (>20%)': '#c0392b'     # Rouge fonc√©\n",
    "    }\n",
    "    \n",
    "    # Tracer chaque cat√©gorie\n",
    "    for cat in labels:\n",
    "        gdf_cat = gdf[gdf['CATEGORIE'] == cat]\n",
    "        if len(gdf_cat) > 0:\n",
    "            gdf_cat.plot(ax=ax, color=colors[cat], edgecolor='black', linewidth=0.8,\n",
    "                        label=f'{cat} ({len(gdf_cat)} depts)')\n",
    "    \n",
    "    # D√©partements sans donn√©es\n",
    "    gdf_sans_donnees = gdf[gdf['CATEGORIE'].isna()]\n",
    "    if len(gdf_sans_donnees) > 0:\n",
    "        gdf_sans_donnees.plot(ax=ax, color='lightgrey', edgecolor='black',\n",
    "                              linewidth=0.8, hatch='//', label=f'Pas de donn√©es ({len(gdf_sans_donnees)})')\n",
    "    \n",
    "    # Ajouter noms des principales villes/r√©gions\n",
    "    capitales = {\n",
    "        'DAKAR': (-17.4467, 14.7645),\n",
    "        'THI√àS': (-16.935, 14.79),\n",
    "        'SAINT-LOUIS': (-16.4896, 16.022),\n",
    "        'KAOLACK': (-16.0758, 14.165),\n",
    "        'ZIGUINCHOR': (-16.2819, 12.564)\n",
    "    }\n",
    "    \n",
    "    for ville, (lon, lat) in capitales.items():\n",
    "        ax.plot(lon, lat, 'v', color='darkblue', markersize=10)\n",
    "        ax.annotate(ville, xy=(lon, lat), xytext=(5, 5),\n",
    "                   textcoords=\"offset points\", fontsize=10, fontweight='bold',\n",
    "                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    ax.set_title('CAT√âGORISATION DU DEGR√â D\\'URBANISATION', fontsize=14, fontweight='bold', pad=15)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # L√©gende am√©lior√©e\n",
    "    ax.legend(title='NIVEAU D\\'URBANISATION', loc='upper left', fontsize=10,\n",
    "              title_fontsize=11, framealpha=0.9, edgecolor='black')\n",
    "    \n",
    "    # √âchelle manuelle\n",
    "    bounds = gdf.total_bounds\n",
    "    scale_x = bounds[0] + (bounds[2] - bounds[0]) * 0.05\n",
    "    scale_y = bounds[1] + (bounds[3] - bounds[1]) * 0.05\n",
    "    scale_deg = 100 / 111\n",
    "    \n",
    "    ax.plot([scale_x, scale_x + scale_deg], [scale_y, scale_y], \n",
    "            color='black', linewidth=3)\n",
    "    ax.plot([scale_x, scale_x], [scale_y-0.05, scale_y+0.05], \n",
    "            color='black', linewidth=2)\n",
    "    ax.plot([scale_x + scale_deg, scale_x + scale_deg], [scale_y-0.05, scale_y+0.05], \n",
    "            color='black', linewidth=2)\n",
    "    ax.text(scale_x + scale_deg/2, scale_y - 0.1, '100 km', \n",
    "            ha='center', va='top', fontsize=9, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Ajouter fl√®che nord\n",
    "    north_x = bounds[0] + (bounds[2] - bounds[0]) * 0.95\n",
    "    north_y = bounds[1] + (bounds[3] - bounds[1]) * 0.95\n",
    "    ax.text(north_x, north_y, 'N', fontsize=14, fontweight='bold',\n",
    "            va='center', ha='center', \n",
    "            bbox=dict(boxstyle='circle', facecolor='white', edgecolor='black'))\n",
    "    \n",
    "    # Statistiques des cat√©gories\n",
    "    cat_stats = df_valides['CATEGORIE'].value_counts()\n",
    "    stats_text = \"R√âPARTITION PAR CAT√âGORIE:\\n\"\n",
    "    total = len(df_valides)\n",
    "    for cat in labels:\n",
    "        count = cat_stats.get(cat, 0)\n",
    "        stats_text += f\"‚Ä¢ {cat.split('(')[0].strip()}: {count} depts ({count/total*100:.1f}%)\\n\"\n",
    "    \n",
    "    # Ajouter top 5 d√©partements par cat√©gorie\n",
    "    stats_text += \"\\nTOP 5 PAR CAT√âGORIE:\\n\"\n",
    "    for cat in ['Tr√®s √©lev√©e (>20%)', '√âlev√©e (10-20%)']:\n",
    "        cat_depts = df_valides[df_valides['CATEGORIE'] == cat]\n",
    "        if len(cat_depts) > 0:\n",
    "            top = cat_depts.nlargest(3, 'PCT_BATI')\n",
    "            stats_text += f\"{cat.split('(')[0]}:\\n\"\n",
    "            for _, dept in top.iterrows():\n",
    "                stats_text += f\"  - {dept['NOM_DEPT']}: {dept['PCT_BATI']:.1f}%\\n\"\n",
    "    \n",
    "    fig.text(0.02, 0.15, stats_text, fontsize=9,\n",
    "             bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9),\n",
    "             verticalalignment='top')\n",
    "    \n",
    "    # L√©gende de la carte\n",
    "    fig.text(0.5, 0.02,\n",
    "             'Source: Analyse Spatiale 2018 | ‚ñ≤ Capitales r√©gionales | Classification: PCT_BATI',\n",
    "             ha='center', fontsize=9, style='italic')\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    plt.savefig(DOSSIER_SORTIE / '06_carte_categories.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úì 06_carte_categories.png\")\n",
    "    plt.close()\n",
    "    \n",
    "# ============================================\n",
    "# MAIN\n",
    "# ============================================\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"VISUALISATION URBANISATION S√âN√âGAL 2018\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Chargement\n",
    "    df, df, gdf_dept, gdf_region = charger_donnees()\n",
    "    \n",
    "    # Si chargement √©chou√©, arr√™ter\n",
    "    if df is None:\n",
    "        print(\"\\n‚ùå Impossible de continuer. Veuillez corriger les chemins.\")\n",
    "        print(f\"   V√©rifiez votre structure de dossiers:\")\n",
    "        print(f\"   {REPERTOIRE_BASE / 'data'}\")\n",
    "        return\n",
    "    \n",
    "    # Stats\n",
    "    stats_descriptives(df)\n",
    "    \n",
    "    # Graphiques\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"G√âN√âRATION DES VISUALISATIONS\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    graphique_distribution(df)\n",
    "    graphique_top_departements(df)\n",
    "    stats_reg = graphique_regions(df)\n",
    "    \n",
    "    # Cartes\n",
    "    carte_departements(df, gdf_dept)\n",
    "    carte_regions(df, gdf_region)\n",
    "    carte_categories(df, gdf_dept)\n",
    "    \n",
    "    # R√©sum√©\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ VISUALISATIONS TERMIN√âES\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nüìÇ Fichiers dans: {DOSSIER_SORTIE}\")\n",
    "    print(\"\\nüìã Fichiers g√©n√©r√©s:\")\n",
    "    print(\"  1. 01_distribution.png - Distribution globale\")\n",
    "    print(\"  2. 02_top_departements.png - Top/Bottom 20\")\n",
    "    print(\"  3. 03_analyse_regions.png - Analyse r√©gionale\")\n",
    "    print(\"  4. 04_carte_departements.png - Carte d√©partements\")\n",
    "    print(\"  5. 05_carte_regions.png - Carte r√©gions\")\n",
    "    print(\"  6. 06_carte_categories.png - Carte cat√©gories\")\n",
    "    print(\"\\n‚ú® Analyse termin√©e avec succ√®s!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484cb51-e4a7-4806-bbed-0b480280a465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
